// Code generated by protoc-gen-grpc-gateway. DO NOT EDIT.
// source: inference_engine.proto

/*
Package pb is a reverse proxy.

It translates gRPC into RESTful JSON APIs.
*/
package pb

import (
	"context"
	"io"
	"net/http"

	"github.com/grpc-ecosystem/grpc-gateway/v2/runtime"
	"github.com/grpc-ecosystem/grpc-gateway/v2/utilities"
	"google.golang.org/grpc"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/grpclog"
	"google.golang.org/grpc/metadata"
	"google.golang.org/grpc/status"
	"google.golang.org/protobuf/proto"
)

// Suppress "imported and not used" errors
var _ codes.Code
var _ io.Reader
var _ status.Status
var _ = runtime.String
var _ = utilities.NewDoubleArray
var _ = metadata.Join

func request_GRPCInferenceService_ModelStreamInfer_0(ctx context.Context, marshaler runtime.Marshaler,
	client GRPCInferenceServiceClient, req *http.Request,
	pathParams map[string]string) (GRPCInferenceService_ModelStreamInferClient, runtime.ServerMetadata, error) {
	var protoReq ModelInferRequest
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	stream, err := client.ModelStreamInfer(ctx, &protoReq)
	if err != nil {
		return nil, metadata, err
	}
	header, err := stream.Header()
	if err != nil {
		return nil, metadata, err
	}
	metadata.HeaderMD = header
	return stream, metadata, nil

}

func request_GRPCInferenceService_ModelStreamInfer_1(ctx context.Context, marshaler runtime.Marshaler,
	client GRPCInferenceServiceClient, req *http.Request,
	pathParams map[string]string) (GRPCInferenceService_ModelStreamInferClient, runtime.ServerMetadata, error) {
	var protoReq ModelInferRequest
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	stream, err := client.ModelStreamInfer(ctx, &protoReq)
	if err != nil {
		return nil, metadata, err
	}
	header, err := stream.Header()
	if err != nil {
		return nil, metadata, err
	}
	metadata.HeaderMD = header
	return stream, metadata, nil

}

func request_GRPCInferenceService_ModelFetchRequest_0(ctx context.Context, marshaler runtime.Marshaler,
	client GRPCInferenceServiceClient, req *http.Request, pathParams map[string]string) (proto.Message,
	runtime.ServerMetadata, error) {
	var protoReq ModelFetchRequestParams
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	msg, err := client.ModelFetchRequest(ctx, &protoReq, grpc.Header(&metadata.HeaderMD),
		grpc.Trailer(&metadata.TrailerMD))
	return msg, metadata, err

}

func local_request_GRPCInferenceService_ModelFetchRequest_0(ctx context.Context, marshaler runtime.Marshaler,
	server GRPCInferenceServiceServer, req *http.Request, pathParams map[string]string) (proto.Message,
	runtime.ServerMetadata, error) {
	var protoReq ModelFetchRequestParams
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	msg, err := server.ModelFetchRequest(ctx, &protoReq)
	return msg, metadata, err

}

func request_GRPCInferenceService_ModelFetchRequest_1(ctx context.Context, marshaler runtime.Marshaler,
	client GRPCInferenceServiceClient, req *http.Request, pathParams map[string]string) (proto.Message,
	runtime.ServerMetadata, error) {
	var protoReq ModelFetchRequestParams
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	msg, err := client.ModelFetchRequest(ctx, &protoReq, grpc.Header(&metadata.HeaderMD),
		grpc.Trailer(&metadata.TrailerMD))
	return msg, metadata, err

}

func local_request_GRPCInferenceService_ModelFetchRequest_1(ctx context.Context, marshaler runtime.Marshaler,
	server GRPCInferenceServiceServer, req *http.Request, pathParams map[string]string) (proto.Message,
	runtime.ServerMetadata, error) {
	var protoReq ModelFetchRequestParams
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	msg, err := server.ModelFetchRequest(ctx, &protoReq)
	return msg, metadata, err

}

func request_GRPCInferenceService_ModelFetchRequest_2(ctx context.Context, marshaler runtime.Marshaler,
	client GRPCInferenceServiceClient, req *http.Request, pathParams map[string]string) (proto.Message,
	runtime.ServerMetadata, error) {
	var protoReq ModelFetchRequestParams
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	msg, err := client.ModelFetchRequest(ctx, &protoReq, grpc.Header(&metadata.HeaderMD),
		grpc.Trailer(&metadata.TrailerMD))
	return msg, metadata, err

}

func local_request_GRPCInferenceService_ModelFetchRequest_2(ctx context.Context, marshaler runtime.Marshaler,
	server GRPCInferenceServiceServer, req *http.Request, pathParams map[string]string) (proto.Message,
	runtime.ServerMetadata, error) {
	var protoReq ModelFetchRequestParams
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	msg, err := server.ModelFetchRequest(ctx, &protoReq)
	return msg, metadata, err

}

func request_GRPCInferenceService_ModelFetchRequest_3(ctx context.Context, marshaler runtime.Marshaler,
	client GRPCInferenceServiceClient, req *http.Request, pathParams map[string]string) (proto.Message,
	runtime.ServerMetadata, error) {
	var protoReq ModelFetchRequestParams
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	msg, err := client.ModelFetchRequest(ctx, &protoReq, grpc.Header(&metadata.HeaderMD),
		grpc.Trailer(&metadata.TrailerMD))
	return msg, metadata, err

}

func local_request_GRPCInferenceService_ModelFetchRequest_3(ctx context.Context, marshaler runtime.Marshaler,
	server GRPCInferenceServiceServer, req *http.Request, pathParams map[string]string) (proto.Message,
	runtime.ServerMetadata, error) {
	var protoReq ModelFetchRequestParams
	var metadata runtime.ServerMetadata

	if err := marshaler.NewDecoder(req.Body).Decode(&protoReq); err != nil && err != io.EOF {
		return nil, metadata, status.Errorf(codes.InvalidArgument, "%v", err)
	}

	msg, err := server.ModelFetchRequest(ctx, &protoReq)
	return msg, metadata, err

}

// RegisterGRPCInferenceServiceHandlerServer registers the mux handlers for service GRPCInferenceService to "mux".
// UnaryRPC     :call GRPCInferenceServiceServer directly.
// StreamingRPC :currently unsupported pending https://github.com/grpc/grpc-go/issues/906.
// Note that using this registration option will cause many gRPC library features to stop working. Consider using RegisterGRPCInferenceServiceHandlerFromEndpoint instead.
func RegisterGRPCInferenceServiceHandlerServer(ctx context.Context, mux *runtime.ServeMux,
	server GRPCInferenceServiceServer) error {

	mux.Handle("POST", pattern_GRPCInferenceService_ModelStreamInfer_0,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			err := status.Error(codes.Unimplemented,
				"streaming calls are not yet supported in the in-process transport")
			_, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
			return
		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelStreamInfer_1,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			err := status.Error(codes.Unimplemented,
				"streaming calls are not yet supported in the in-process transport")
			_, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
			return
		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelFetchRequest_0,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			var stream runtime.ServerTransportStream
			ctx = grpc.NewContextWithServerTransportStream(ctx, &stream)
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateIncomingContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelFetchRequest",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/ic/grpcinferenceservice/modelfetchrequest"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := local_request_GRPCInferenceService_ModelFetchRequest_0(annotatedContext, inboundMarshaler,
				server, req, pathParams)
			md.HeaderMD, md.TrailerMD = metadata.Join(md.HeaderMD, stream.Header()), metadata.Join(md.TrailerMD,
				stream.Trailer())
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelFetchRequest_0(annotatedContext, mux, outboundMarshaler, w, req, resp,
				mux.GetForwardResponseOptions()...)

		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelFetchRequest_1,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			var stream runtime.ServerTransportStream
			ctx = grpc.NewContextWithServerTransportStream(ctx, &stream)
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateIncomingContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelFetchRequest",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/ic/grpcinferenceservice/modelsendresponse"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := local_request_GRPCInferenceService_ModelFetchRequest_1(annotatedContext, inboundMarshaler,
				server, req, pathParams)
			md.HeaderMD, md.TrailerMD = metadata.Join(md.HeaderMD, stream.Header()), metadata.Join(md.TrailerMD,
				stream.Trailer())
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelFetchRequest_1(annotatedContext, mux, outboundMarshaler, w, req, resp,
				mux.GetForwardResponseOptions()...)

		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelFetchRequest_2,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			var stream runtime.ServerTransportStream
			ctx = grpc.NewContextWithServerTransportStream(ctx, &stream)
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateIncomingContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelFetchRequest",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/dataserver/grpcinferenceservice/modelfetchrequest"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := local_request_GRPCInferenceService_ModelFetchRequest_2(annotatedContext, inboundMarshaler,
				server, req, pathParams)
			md.HeaderMD, md.TrailerMD = metadata.Join(md.HeaderMD, stream.Header()), metadata.Join(md.TrailerMD,
				stream.Trailer())
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelFetchRequest_2(annotatedContext, mux, outboundMarshaler, w, req, resp,
				mux.GetForwardResponseOptions()...)

		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelFetchRequest_3,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			var stream runtime.ServerTransportStream
			ctx = grpc.NewContextWithServerTransportStream(ctx, &stream)
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateIncomingContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelFetchRequest",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/dataserver/grpcinferenceservice/modelsendresponse"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := local_request_GRPCInferenceService_ModelFetchRequest_3(annotatedContext, inboundMarshaler,
				server, req, pathParams)
			md.HeaderMD, md.TrailerMD = metadata.Join(md.HeaderMD, stream.Header()), metadata.Join(md.TrailerMD,
				stream.Trailer())
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelFetchRequest_3(annotatedContext, mux, outboundMarshaler, w, req, resp,
				mux.GetForwardResponseOptions()...)

		})

	return nil
}

// RegisterGRPCInferenceServiceHandlerFromEndpoint is same as RegisterGRPCInferenceServiceHandler but
// automatically dials to "endpoint" and closes the connection when "ctx" gets done.
func RegisterGRPCInferenceServiceHandlerFromEndpoint(ctx context.Context, mux *runtime.ServeMux, endpoint string,
	opts []grpc.DialOption) (err error) {
	conn, err := grpc.NewClient(endpoint, opts...)
	if err != nil {
		return err
	}
	defer func() {
		if err != nil {
			if cerr := conn.Close(); cerr != nil {
				grpclog.Errorf("Failed to close conn to %s: %v", endpoint, cerr)
			}
			return
		}
		go func() {
			<-ctx.Done()
			if cerr := conn.Close(); cerr != nil {
				grpclog.Errorf("Failed to close conn to %s: %v", endpoint, cerr)
			}
		}()
	}()

	return RegisterGRPCInferenceServiceHandler(ctx, mux, conn)
}

// RegisterGRPCInferenceServiceHandler registers the mux handlers for service GRPCInferenceService to "mux".
// The handlers forward requests to the grpc endpoint over "conn".
func RegisterGRPCInferenceServiceHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {
	return RegisterGRPCInferenceServiceHandlerClient(ctx, mux, NewGRPCInferenceServiceClient(conn))
}

// RegisterGRPCInferenceServiceHandlerClient registers the mux handlers for service GRPCInferenceService
// to "mux". The handlers forward requests to the grpc endpoint over the given implementation of "GRPCInferenceServiceClient".
// Note: the gRPC framework executes interceptors within the gRPC handler. If the passed in "GRPCInferenceServiceClient"
// doesn't go through the normal gRPC flow (creating a gRPC client etc.) then it will be up to the passed in
// "GRPCInferenceServiceClient" to call the correct interceptors.
func RegisterGRPCInferenceServiceHandlerClient(ctx context.Context, mux *runtime.ServeMux,
	client GRPCInferenceServiceClient) error {

	mux.Handle("POST", pattern_GRPCInferenceService_ModelStreamInfer_0,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelStreamInfer",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/ic/grpcinferenceservice/modelstreaminfer"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := request_GRPCInferenceService_ModelStreamInfer_0(annotatedContext, inboundMarshaler, client,
				req, pathParams)
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelStreamInfer_0(annotatedContext, mux, outboundMarshaler, w, req,
				func() (proto.Message, error) { return resp.Recv() }, mux.GetForwardResponseOptions()...)

		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelStreamInfer_1,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelStreamInfer",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/dataserver/grpcinferenceservice/modelstreaminfer"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := request_GRPCInferenceService_ModelStreamInfer_1(annotatedContext, inboundMarshaler, client,
				req, pathParams)
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelStreamInfer_1(annotatedContext, mux, outboundMarshaler, w, req,
				func() (proto.Message, error) { return resp.Recv() }, mux.GetForwardResponseOptions()...)

		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelFetchRequest_0,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelFetchRequest",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/ic/grpcinferenceservice/modelfetchrequest"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := request_GRPCInferenceService_ModelFetchRequest_0(annotatedContext, inboundMarshaler,
				client, req, pathParams)
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelFetchRequest_0(annotatedContext, mux, outboundMarshaler, w, req, resp,
				mux.GetForwardResponseOptions()...)

		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelFetchRequest_1,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelFetchRequest",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/ic/grpcinferenceservice/modelsendresponse"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := request_GRPCInferenceService_ModelFetchRequest_1(annotatedContext, inboundMarshaler,
				client, req, pathParams)
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelFetchRequest_1(annotatedContext, mux, outboundMarshaler, w, req, resp,
				mux.GetForwardResponseOptions()...)

		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelFetchRequest_2,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelFetchRequest",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/dataserver/grpcinferenceservice/modelfetchrequest"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := request_GRPCInferenceService_ModelFetchRequest_2(annotatedContext, inboundMarshaler,
				client, req, pathParams)
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelFetchRequest_2(annotatedContext, mux, outboundMarshaler, w, req, resp,
				mux.GetForwardResponseOptions()...)

		})

	mux.Handle("POST", pattern_GRPCInferenceService_ModelFetchRequest_3,
		func(w http.ResponseWriter, req *http.Request, pathParams map[string]string) {
			ctx, cancel := context.WithCancel(req.Context())
			defer cancel()
			inboundMarshaler, outboundMarshaler := runtime.MarshalerForRequest(mux, req)
			var err error
			var annotatedContext context.Context
			annotatedContext, err = runtime.AnnotateContext(ctx, mux, req,
				"/language_inference.GRPCInferenceService/ModelFetchRequest",
				runtime.WithHTTPPathPattern("/comate/v1/grpc/dataserver/grpcinferenceservice/modelsendresponse"))
			if err != nil {
				runtime.HTTPError(ctx, mux, outboundMarshaler, w, req, err)
				return
			}
			resp, md, err := request_GRPCInferenceService_ModelFetchRequest_3(annotatedContext, inboundMarshaler,
				client, req, pathParams)
			annotatedContext = runtime.NewServerMetadataContext(annotatedContext, md)
			if err != nil {
				runtime.HTTPError(annotatedContext, mux, outboundMarshaler, w, req, err)
				return
			}

			forward_GRPCInferenceService_ModelFetchRequest_3(annotatedContext, mux, outboundMarshaler, w, req, resp,
				mux.GetForwardResponseOptions()...)

		})

	return nil
}

var (
	pattern_GRPCInferenceService_ModelStreamInfer_0 = runtime.MustPattern(runtime.NewPattern(1,
		[]int{2, 0, 2, 1, 2, 2, 2, 3, 2, 4, 2, 5},
		[]string{"comate", "v1", "grpc", "ic", "grpcinferenceservice", "modelstreaminfer"}, ""))

	pattern_GRPCInferenceService_ModelStreamInfer_1 = runtime.MustPattern(runtime.NewPattern(1,
		[]int{2, 0, 2, 1, 2, 2, 2, 3, 2, 4, 2, 5},
		[]string{"comate", "v1", "grpc", "dataserver", "grpcinferenceservice", "modelstreaminfer"}, ""))

	pattern_GRPCInferenceService_ModelFetchRequest_0 = runtime.MustPattern(runtime.NewPattern(1,
		[]int{2, 0, 2, 1, 2, 2, 2, 3, 2, 4, 2, 5},
		[]string{"comate", "v1", "grpc", "ic", "grpcinferenceservice", "modelfetchrequest"}, ""))

	pattern_GRPCInferenceService_ModelFetchRequest_1 = runtime.MustPattern(runtime.NewPattern(1,
		[]int{2, 0, 2, 1, 2, 2, 2, 3, 2, 4, 2, 5},
		[]string{"comate", "v1", "grpc", "ic", "grpcinferenceservice", "modelsendresponse"}, ""))

	pattern_GRPCInferenceService_ModelFetchRequest_2 = runtime.MustPattern(runtime.NewPattern(1,
		[]int{2, 0, 2, 1, 2, 2, 2, 3, 2, 4, 2, 5},
		[]string{"comate", "v1", "grpc", "dataserver", "grpcinferenceservice", "modelfetchrequest"}, ""))

	pattern_GRPCInferenceService_ModelFetchRequest_3 = runtime.MustPattern(runtime.NewPattern(1,
		[]int{2, 0, 2, 1, 2, 2, 2, 3, 2, 4, 2, 5},
		[]string{"comate", "v1", "grpc", "dataserver", "grpcinferenceservice", "modelsendresponse"}, ""))
)

var (
	forward_GRPCInferenceService_ModelStreamInfer_0 = ForwardResponseStream

	forward_GRPCInferenceService_ModelStreamInfer_1 = ForwardResponseStream

	forward_GRPCInferenceService_ModelFetchRequest_0 = runtime.ForwardResponseMessage

	forward_GRPCInferenceService_ModelFetchRequest_1 = runtime.ForwardResponseMessage

	forward_GRPCInferenceService_ModelFetchRequest_2 = runtime.ForwardResponseMessage

	forward_GRPCInferenceService_ModelFetchRequest_3 = runtime.ForwardResponseMessage
)
